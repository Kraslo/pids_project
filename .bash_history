cd..
cd .. 
cd kafkadocker/
dir
nano Dockerfile
nano Dockerfile.save 
sudo docker ps
sudo docker rm -f fbc
dh -h
df -h
ls
nano csv_to_airflow.py 
docker compose up
sudo docker compose up
docker compose-up
docker-compose up
ls
cd compose_cluster/
ls
docker compose up
docker-compose up
cd ..
cd kafka docker
cd kafkadocker
ls
cd ..
cd compose_cluster/
ls
nano docker-compose.yaml
cd ..
ls
airflowdocker
cd airflowdocker
nano docker-compose.yaml
docker-compose up
sudo docker-compose up
nano docker-compose.yaml
cd ..
ls
cd airfloedocker
ls
cd airflow
ls
mv csv_to_airflow.py dags
mv csv_to_airflow.py dags/
cd ..
mv csv_to_airflow.py dags/
mv csv_to_airflow.py airflow/dags/
cd airflow
ls
cd dags
ls
cd ..
ls
mv rows.csv airflow/dags/
mv prueba_airflow.py airflow/dags/
cd airflow
cd dags
ls
mv csv_to_airflow.py .
mv csv_to_airflow.py ~/
ls
cd ..
ls
cd airflowdocker
ls
mv docker-compose-yaml ~/
mv docker-compose.yaml ~/
mv docker-compose.yaml /dags/
mv docker-compose.yaml airflow/dags/
ls
mv docker-compose.yaml ~/
cd ..
code
visual studio code
ls
cd airflowdocker
ls
cd ..
python3 csv_to_airflow.py 
nano csv_to_airflow.py 
python3 csv_to_airflow.py 
nano csv_to_airflow.py 
python3 csv_to_airflow.py 
airflow webserver --port 8080
python3 csv_to_airflow.py 
ls
nano csv_to_airflow.py 

nano csv_to_airflow.py 
nano prueba_airflow.py
python3 prueba_airflow.py 
pip install airflow.operator
nano prueba_airflow.py
python3 csv_to_airflow.py 
python3 prueba_airflow.py 
nano prueba_airflow.py 
python3 prueba_airflow.py 
nano prueba_airflow.py 
python3 prueba_airflow.py 
nano prueba_airflow.py 
python3 prueba_airflow.py 
ls
cd airflowdocker/
ls
cd airflowfiledir/
ls
cd ..
cd .. 
python3 prueba_airflow.py 
ls
cd airflow
ls
cd dags
ls
cd ..
ls
cd ..
ls
cd airflowdocker/
ls
nano docker-compose.yaml
dir
cd kafkadocker/
cd ..
cat csv_to_airflow.py 
dir
cd kafkadocker/
dir
cat Dockerfile
dir
sudo nano Dockerfile
sudo nano start-script.sh
docker build -t Dockerfile .
dir
docker build -t .
docker build .
sudo docker build .
docker build -t pidskafka .
sudo docker build -t pidskafka .
dir
mv start-script.sh start-kafka.sh
sudo mv start-script.sh start-kafka.sh
sudo docker buld -t pidskafka .
sudo docker build -t pidskafka .
cd ..
cd kafkadocker/
sudo nano start-kafka.sh 
sudo nano Dockerfile
sudo docker build -t pidskafka .
cd ..
dir
mkdir compose_cluster
cd compose_cluster/
sudo nano dockker-compose.yaml
cd ..
dir
cd air
cd airflow
dir
cd ..
cd airflowdocker/
cat docker-compose.yaml 
cd ..
cd compose_cluster/
sudo nano docker-compose.yaml
docker compose up -d
sudo nano docker-compose.yaml 
docker compose up -d
sudo nano docker-compose.yaml 
docker compose up -d
sudo docker compose up -d
sudo docker ps
clear
sudo docker ps
htop
sudo docker exec -it kafka bash
sudo docker exec -it 9c4 bash
cd ..
dir
cd kafkadocker/
dir
cat start-kafka.sh 
sudo docker exec -it 9c4 bash
sudo docker ps
cd ..
dir
cd airflow
dir
cd dags
dir
ls -la
cat prueba_airflow.py 
dir
cd ..
dir
cd airflow
dir
cd ..
cd airflowdocker/
docker compose restart
sudo docker compose restart
sudo docker ps
dir
cd ..
cd airflow
dir
cd dags
dir
mv prueba_airflow.py dag_airflow.py
cd ..
cd airflowdocker/
docker compose restart
sudo docker compose restart
sudo docker ps
sudo docker exec -it 1b3 bash
ls
nano csv_to_airflow.py 
cd airflow
docker compose up --build
docker-compose up --build
docker-compose up
ls
cd ..
ls
cd airflowdocker
docker-compose up
docker-compose up --build
ls
nano docker-compose.yaml
ls
cd ..
ls
cd airflow
ls
mkdir dags
ls
cd ..
ls
nano prueba_airflow.py 
cd airflow
ls
cd dags
ls
cd ..
ls
cd airflowdocker
ls
cd ..
ls
cd airflow
ls
cd dags
ls
docker cp
cd ..
cd airflowdocker
ls
cd ..
cd airflow
cd dags
ls
cd ..
docker ps
cd ..
docker ps
sudo docker ps
ls
sudo docker-compose.yaml
sudo docker compose.yaml
sudo docker-compose up
sudo docker compose up
sudo docker compose-up
sudo docker-compose up
ls
cd compose_cluster
ls
sudo docker-compose up
ls
cd airflow
ls
docker ps
sudo docker ps
docker exec -it airflowdocker-airflow-scheduler-1
docker exec -it airflowdocker-airflow-scheduler-1 /bin/bash
sudo docker exec -it airflowdocker-airflow-scheduler-1 /bin/bash
cd airflowdocker
sudo docker-compose up
cd ..
cd airflow
ls
cd dags
ls
nano dag_airflow.py
sudo docker-compose up
cd ..
ls
cd ..
ls
cd airflowdocker
ls
nano docker-compose.yaml
sudo docker-compose up
cd ..
ls
d compose_cluster
cd compose_cluster
ls
nano docker-compose.yaml 
cd ..
ls
cd airflowdocker
sudo docker-compose up
sudo docker compose down
sudo docker-compose down
cd ..
cd airflow
cd dags
ls
nano dag_airflow.py 
ls
docker ps
ls
docker compose down
sudo docker compose down
ls
cd kafkadocker
ls
nano start-kafka.sh
cd ..
ls
cd docker
ls
cd ..
ls
cat csv_to_airflow.py.save
cat csv_to_airflow.py
rm csv_to_airflow.py.save
ls
tree
tree -a
sudo pacman -S tree
tree --version
sudo apt update
sudo apt install tree
tree
ls
cd airflow
ls
cat airflow.db
cd ..
ls
nano airflowdocker
rm airflowdocker
cd airflowdocker
ls
nano docker-compose.yaml
docker-compose up
sudo docker compose up
ls
docker compose down
sudo docker compose down
sudo docker compose up
docker ps
docker compose down
sudo docker compose down
sudo docker compose up
docker compose down
sudo docker compose down
nano docker-compose.yaml
sudo docker compose up
nano docker-compose.yaml
mv docker-compose.yaml dags/
sudo mv docker-compose.yaml dags/
cd dags
ls
sudo mv docker-compose.yaml airflowdocker/
sudo mv docker-compose.yaml /airflowdocker/
sudo mv docker-compose.yaml ..
ls
cd ..
ls
sudo nano docker-compose.yaml
sudo docker-compose up
docker compose down
sudo docker compose down
docker-compose up
cd airflow
ls
cd ..
docker airflow
ls
cd airflowdocker
ls
cd ..
cd compose_cluster
ls
docker-compose up
sudo docker-compose up
docker ps
sudo docker ps
cd ..
ls
cd docker
ls
dags
cd dags
ls
cs ..
cd ..
cd airflowdocker
ls
sudo docker-compose up
ls
cd airflowdocker/
ls
cat docker-compose.yaml
ls
cd airflow
ls
cd ..
nano csv_to_airflow.py
python3 csv_to_airflow.py 
nano csv_to_airflow.py
cd airflow
cd dags
ls
nano dag_airflow.py 
cd ..
ls
nano csv_to_airflow.py 
ls
dir
cd airflow
dir
cd dags
dir
mv rows.csv ..
cd ..
dir
cd airflow
cd ..
cd airflowdocker/
dir
sudo docker compose up -d
dir
tree airflow
sudo docker ps
sudo docker volume ls
sudo docker logs bd5
cd airflowdocker/
dir
nano docker-compose.y
nano docker-compose.yaml 
sudo nano docker-compose.yaml 
dir
cd airflowfiledir/
dir
sudo nano ../docker-compose.yaml 
ls -la
cd ..
ls -la
cat .env
sudo nano .env
cd ..
dir
cd airflow
dir
cd ..
mv airflow airflowdocker/
sudo mv airflow airflowdocker/
dir
cd airflowdocker/
dir
sudo nano .env
sudo docker compose restart
sudo nano .env
cd airflow
ls
cd dags
dir
cd ..
dir
ls -la
cd ..
sudo cat .env
pwd
sudo nano docker-compose.ya
sudo nano docker-compose.yaml 
AIRFLOW_PROJ_DIR
cat ${AIRFLOW_PROJ_DIR}
sudo nano docker-compose.yaml 
cd airflow
dir
cd ..
dir
cd airflow
cd ..
cd airflowfiledir/
dir
cd dags
dir
cd ..
rm -rf airflow
sudo mv airflow/*.py ,
sudo mv airflow/dags/*.py ,
sudo mv airflow/dags/*.py .
cd air
cd airflow
cd dagas
cd dags
dir
ls 
cd ..
dir
mv check_csv_dag.py airflowdocker/airflowfiledir/
sudo mv check_csv_dag.py airflowdocker/airflowfiledir/dags
cd airflowdocker/
dir
sudo nano .env
sudo docker compose restart
AIRFLOW_PROJ_DIR=/home/pids_user/airflowdocker/airflowfiledir
sudo docker compose restart
sudo nano docker-compose.yaml 
dir
cd dags
dir
cd ..
mv airflowfiledir/dags/check_csv_dag.py dags
sudo mv airflowfiledir/dags/check_csv_dag.py dags
sudo docker compose restart
printenv
_
cd HOME
sudo tree .
ls
ls -la
sudo rm -rf airflow
sudo rm -rf airflowfiledir
ls
sudo nano .env
sudo nano docker-compose.yaml 
ls -la
docker compose --env-file
docker compose
docker compose --env-file .env restart
sudo docker compose --env-file .env restart
sudo nano .env
dir
mkdir airflowfildir
sudo mkdir airflowfiledir
dir
cd airflowfiledir/
dir
cd dags
dir
cd ..
sudo mv dags/check_csv_dag.py  airflowfiledir/dags
sudo docker compose --env-file .env restart
dir
cd airflowfiledir/dags
touch __init__.py
sudo touch __init__.py
ls
ls -la
cd ..
sudo nano .evn
sudo nano .nv
sudo nano .env
sudo nano docker-compose.yaml 
sudo docker compose config
sudo docker compose config | grep dir
sudo docker commpose config | grep dag
sudo docker compose config | grep dag
sudo ls airflowfiledir/dags
sudo cat airflowfiledir/dags/check_csv_dag.py 
sudo docker exec -it airflowdocker-airflow-scheduler-1 ls /opt/airflow/dags
sudo chmod 644 airflowfiledir/dags/check_csv_dag.py 
sudo docker exec -it airflowdocker-airflow-scheduler-1 airflow dags list
dir
cd airflowfiledir/
dir
cd dags
dir
sudo nano check_csv_dag.py 
sudo docker exec -it airflowdocker-airflow-scheduler-1 airflow dags unpause check_and_process_csv_dag
sudo docker exec -it airflowdocker-airflow-scheduler-1 airflow dags list
dir
cd ..
sudo docker compose down
sudo docker compose up -d
sudo docker compose down
sudo docker compose up airflowdocker-airflow-init-1
sudo docker ps -a
sudo docker compose up -d
sudo docker ps
dir
cd ..
sudo docker rm -f docker-airflow-scheduler-1
sudo docker rm -f docker-airflow-webserver-1
sudo docker rm -f docker-airflow-worker-1
sudo docker rm -f docker-airflow-triggerer-1
sudo docker rm -f docker-redis-1
sudo docker rm -f docker-postgres-1
sudo docker ps
cd airflowdocker/
sudo nano docker-compose.yaml 
sudo docker compose restart
sudo docker ps
sudo docker compose down
sudo docker compose up --no-cache
sudo docker compose up -d
sudo docker ps
sudo docker logs airflowdocker-airflow-scheduler-1
dir
cd airflowfiledir/
cd dags
sudo nano check_csv_dag.py 
sudo nano -ET2 check_csv_dag.py 
sudo cat check_csv_dag.py 
pids_user@kraslo:~/airflowdocker/airflowfiledir/dags$ sudo cat check_csv_dag.py
from airflow import DAG
from airflow.operators.python import PythonOperator  # Corregido para usar el nuevo PythonOperator
from airflow.utils.dates import days_ago
import os
import time
import subprocess
from kafka import KafkaProducer
# Ruta del archivo CSV que vamos a chequear
CSV_FILE_PATH = "/app/rows.csv"
# Ruta del script de procesamiento
SCRIPT_PATH = "/app/script1.py"
def check_csv_update():
def send_csv_file():
dir
mv check_csv_dag.py check_csv_dag.py.old
sudo mv check_csv_dag.py check_csv_dag.py.old
sudo nano check_csv_dag.py
dir
cd compose_cluster/
dir
cd ..
cd kafkadocker/
dir
sudo cat start-kafka.sh 
sudo nano start-kafka.sh 
sudo docker image ls
sudo docker build -t pidskafka .
cd ..
dir
cd compose_cluster/
dir
sudo cat docker-compose.yaml 
cd ..
cd airflowdocker/
cd airflowfiledir/
sudo nano dags/check_csv_dag.py
cd ../..
cd compose_cluster/
sudo docker compose up -d
sudo cat docker-compose.yaml 
sudo nano docker-compose.yaml 
sudo docker compose up -d
sudo docker volume ls
docker volume inspect hdfs_docker_hadoop_namenode
sudo docker volume inspect hdfs_docker_hadoop_namenode
sudo docker volume inspect compose_cluster_hadoop_datanode
cd /var/lib/docker/volumes/compose_cluster_hadoop_datanode/_data
sudo cd /var/lib/docker/volumes/compose_cluster_hadoop_datanode/_data
/var/lib/docker/volumes/compose_cluster_hadoop_datanode/_data
su
sudo cat docker-compose.yaml 
sudo nano ../airflowdocker/airflowfiledir/dags/check_csv_dag.py
cd ..
cd airflowdocker/
sudo nano docker-compose.yaml 
sudo docker ps
sudo nano docker-compose.yaml 
ls -la
sudo nano Dockerfile
sudo docker build -t pidsairflow .
sudo nano docker-compose.yaml 
sudo docker image ls
sudo nano Dockerfile 
cd airflowdocker/
sudo nano Dockerfile
sudo docker build -t pidsairflow .
sudo nano Dockerfile
sudo docker build -t pidsairflow .
sudo nano Dockerfile
sudo docker build -t pidsairflow .
sudo nano Dockerfile
sudo docker build -t pidsairflow .
sudo nano Dockerfile
sudo docker build -t pidsairflow .
sudo docker build --no-cache -t pidsairflow .
sudo nano Dockerfile
sudo docker build --no-cache -t pidsairflow .
sudo docker build -t pidsairflow . --no-cache --progress=plain
sudo nano Dockerfile
sudo docker build -t pidskafka .
sudo nano Dockerfile
sudo docker build -t pidskafka .
sudo nano Dockerfile
sudo docker build -t pidskafka .
sudo nano Dockerfile
sudo docker build -t pidskafka .
sudo mv Dockerfile Dockerfile.old
sudo nano Dockerfile
sudo docker build -t pidskafka .
did
dir
sudo nano docker-compose.yaml 
cd ..
cd compose_cluster/
cd ..
cd airflowdocker/
cd airflowfiledir/
cd dags
sudo cat check_csv_dag.py
sudo docker ps
cd ..
cd compose_cluster/
sudo nano docker-compose.yaml 
sudo docker compose up -d
dir
sudo docker ps
sudo nano docker-compose.yaml 
sudo docker compose down
sudo docker compose up -d
sudo docker compose up -d --remove-orphans
sudo docker ps
sudo nano docker-compose.yaml 
sudo docker compose up -d --remove-orphans
sudo docker ps
sudo nano docker-compose.yaml 
sudo docker compose up -d --remove-orphans
sudo docker ps
curl spark-master:8080
sudo cat docker-compose.yaml 
sudo nano docker-compose.yaml 
sudo docker compose up -d
sudo docker ps
sudo docker logs compose_cluster-spark-worker-1-1
sudo nano docker-compose.yaml 
sudo docker compose up -d
sudo docker ps
sudo nano docker-compose.yaml 
dir
mkdir sparkprograms
mv ../script1.py .
dir
docker exec -it spark-master /bin/bash
sudo docker exec -ít spark-master bash
sudo docker exec  -it spark-master bash
sudo nano docker-compose.yaml 
dir
mv script1.py sparkprograms/
dir
sudo nano docker-compose.yaml 
sudo docker compose up -d
dir
docker exec -it spark-master bash
sudo docker exec -it spark-master bash
sudo docker ps
sudo docker exec -it compose_cluster-spark-worker-1-1 pip install pymongo
sudo docker exec -it compose_cluster-spark-worker-2-1 pip install pymongo
sudo docker exec -it spark-master bash
dir
sudo nano docker-compose.yaml 
dir
cd ..
mkdir sparkscala
sudo nano Dockerfile
dir
mv compose_cluster/sparkprograms/script1.py sparkscala
cd sparkscala/
dir
cd ..
dir
sudo cat Dockerfile 
sudo mv Dockerfile sparkscala 
sudo nano Do
cd sparkscala/
sudo nano Dockerfile 
sudo docker build -t sparkscala .
dh -H
df -H
sudo nano Dockerfile 
sudo docker build -t sparkscala .
ls
sudo nano start-spark.sh
sudo docker build -t sparkscala .
cd ..
sudo nano compose_cluster/docker-compose.yaml 
mkdir mongotainer
cd mongotainer/
cd ..
sudo nano docker/
sudo rm -rf mongotainer
dir
cd docker/
dir
cd dags
dir
ls -la
cd ..
sudo rm -rf docker
dir
sudo rm -rf __pycache__/
dir
cd compose_cluster/
sudo nano docker-compose.yaml 
sudo docker compose up -d
sudo nano docker-compose.yaml 
sudo docker compose up -d
sudo docker ps
sudo docker  rm -f 782
sudo docker  rm -f 75e
sudo docker  rm -f e0d
sudo docker compose up -d
sudo docker ps -a
sudo docker compose up -d
sudo nan odo
sudo nano docker-compose.yaml 
sudo docker compose up -d
sudo docker rm spark-master
sudo docker compose up -d --remove-orphans
sudo docker container prune
sudo docker compose up -d --remove-orphans
sudo docker images ls
sudo docker images
sudo docker image rm 42e
dir
sudo docker compose up -d
sudo docker rmi bde2020/spark-master:latest
sudo docker compose up -d
sudo docker rmi -f bde2020/spark-master:latest
sudo docker ps
sudo docker rm -f spark-master
sudo docker ps -a
sudo nano docker-compose.yaml 
sudo docker compose up -d
sudo nano docker-compose.yaml 
sudo cat docker-compose.yaml 
cd ..
mkdir data_volume
cd  compose_cluster/
sudo docker compose up -d
sudo docker ps
cd ..
dir
pip install os
cd sparkscala/
sudo nano requirements.txt
sudo nano Dockerfile 
sudo docker build -t sparkscala .
sudo nano requirements.txt 
sudo docker build -t sparkscala .
dir
sudo docker ps
cd ..
cd compose_cluster/
sudo cat docker-compose.yaml 
sudo docker image ls
sudo docker compose up -d
sudo docker ps
cd ..
dir
cd data_volume/
sudo nano script1.py
cd ..
sudo docker ps
cd compose_cluster/
sudo docker compose restart
cd ..
cd sparkscala/
dir
sudo nano start-spark.sh 
cat ../compose_cluster/docker-compose.yaml 
sudo nano s
sudo nano start-spark.sh 
sudo docker build -t sparkscala .
cd ../compose_cluster/
sudo docker compose down
sudo docker compose up -d
sudo docker ps
sudo docker logs spark-master
cd ../sparkscala/
sudo cat start-spark.sh 
sudo nano start-spark.sh 
sudo cat start-spark.sh 
sudo docker build -t sparkscala .
cd ..
cd compose_cluster/
sudo docker compose down
sudo docker compose up -d
sudo docker logs spark-master
cat ../sparkscala/Dockerfile 
nano ..
cd ..
cd sparkscala/
sudo nano Dockerfile 
sudo docker build -t sparkscala .
cd ..
cd compose_cluster/
sudo docker compose down
sudo docker compose up -d
sudo docker logs spark-master
cd ..
cd sparkscala/
sudo nano Dockerfile 
sudo nano start-spark.sh 
sudo docker build -t sparkscala .
cd ..
cd compose_cluster/
sudo docker compose down
sudo docker compose up -d
sudo docker logs spark-master
cat ../sparkscala/script1.py
rm -rf ../sparkscala/script1.py 
cd ..
dir
cd data_volume/
dir
cd ..
cd compose_cluster/
sudo nano docker-compose.yaml 
mv ../data_volume/script1.py ../sparkscala/
cd ..
cd sparkscala/
sudo docker build -t sparkscala .
cd ../compose_cluster
sudo docker compose down
sudo docker compose up -d --remove-orphans
sudo docker logs spark-master
cd ..
cd sparkscala/
sudo nano script1.py 
sudo nano requirements.txt 
sudo docker build -t sparkscala .
cd ..
cd compose_cluster/
sudo docker compose down
sudo docker compose up -d
sudo docker logs spark-master
sudo docker ps
cd ..
cd sparkscala/
sudo nano script1.py 
cd ..
nano compose_cluster/docker-compose.yaml 
sudo nano compose_cluster/docker-compose.yaml 
cd sparkscala/
sudo nano script1.py 
sudo docker build -t sparkscala .
sudo docker container ls
sudo docker ps -a
sudo docker image prune
sudo docker build -t sparkscala .
df -H
cd ..
cd compose_cluster/
sudo docker compose down
sudo docker compose up -d --remove-orphans
sudo docker logs spark-master
sudo docker ps
curl pidskafka:8082
sudo docker ps
sudo docker exec -it spark-master bash
sudo nano docker-compose.yaml 
sudo docker exec -it spark-master bash
sudo docker logs pidskafka
sudo docker ps
sudo docker restart pidskafka
sudo docker logs pidskafka
cd ..
cd kafr
cd kafkadocker/
sudo nano start-kafka.sh 
sudo docker rm -f pidskafka
sudo docker compose up -d
cd ..
cd compose_cluster/
sudo docker compose up -d
sudo docker logs pidskafka
sudo docker ps
sudo docker rm -f spark-master
sudo docker rm -f compose_cluster-sparkscala-worker1-1
sudo docker rm -f compose_cluster-sparkscala-worker1-2
sudo docker compose up -d
sudo docker logs spark-master
sudo nano docker-compose.yaml 
sudo docker rm -f pidskafka
sudo docker rm -f spark-master
sudo docker rm -f compose_cluster-sparkscala-worker1-1
sudo docker rm -f compose_cluster-sparkscala-worker1-2
sudo docker compose up -d
sudo docker logs spark-master
sudo docker rm -f spark-master
sudo docker rm -f compose_cluster-sparkscala-worker1-1
sudo docker rm -f compose_cluster-sparkscala-worker1-2
sudo docker compose up -d
sudo docker logs spark-master
sudo docker ps
sudo cat ../sparkscala/start-spark.sh 
sudo cat ../sparkscala/script1.py 
sudo docker ps
sudo docker logs pidskafka
cd ..
cd sparkscala/
sudo nano script1.py 
sudo docker build -t sparkscala .
sudo docker image prune
cd ..
sudo cd compose_cluster/
cd compose_cluster/
sudo docker compose down
sudo docker compose up -d --remove-orphans
sudo docker logs spark-master
sudo docker logs pidskafka
cd ..
cd air
cd airflowdocker/
dir
sudo nano Dockerfile
sudo rm -rf Dockerfile
sudo rm -rf Dockerfile.old
sudo rm -rf Dockerfile.save
dir
sudo nano docker-compose.yaml
cd airflowfiledir/
dir
sudo nano dags/check_csv_dag.py
sudo cat dags/check_csv_dag.py
dir
nano dags/check_csv_dag2.py
cd ..
cd sparkscala/
sudo nano Dockerfile 
mv Dockerfile Dockerfile.old
sudo nano Dockerfile
sudo docker build -t sparkscala .
sudo nano sshd_config
sudo docker build -t sparkscala .
cd ..
cd compose_cluster/
sudo docker compose down
sudo docker compose up -d
dir
cd ..
cd airflowdocker/
dir
sudo nano Dockerfile
sudo nano sshdconfig
cat docker-compose.yaml 
dir
sudo rm -rf Dockerfile 
sudo nano Dockerfile
sudo nano sshd_config
sudo nano start-ssh.sh
sudo nano Dockerfile 
sudo docker build -t airflowpids .
sudo nano docker-compose.yaml 
sudo docker compose down 
sudo docker compose up -d
sudo cat Dockerfile 
docker run -it --entrypoint /bin/bash apache/airflow:2.10.2
sudo docker run -it --entrypoint /bin/bash apache/airflow:2.10.2
sudo nano Dockerfile 
sudo docker image prune
sudo docker build -t airflowpids .
sudo docker compose down
sudo docker compose up -d --remove-orphans
sudo docker ps
dir
sudo nano requirements.txt
sudo docker image prune
dir
cd airflowfiledir/
dir
cd dagsa
cd dags
sudo nano check_csv_dag.py
dir
sudo nano check_csv_dag.py
sudo nano check_csv_dag.py.old 
sudo mv check_csv_dag.py check_csv_dag.py.old2
dir
sudo nano check_csv_dag.py
cd ..
sudo docker compose restart
sudo docker ps
sudo nano .env
sudo nano Dockerfile 
sudo docker image prune
sudo docker build -t airflowpids .
dir
sudo cat requirements.txt 
sudo nano requirements.txt 
sudo docker build -t airflowpids .
sudo nano Dockerfile 
sudo docker build -t airflowpids .
sudo docker compose down
sudo docker compose up -d --remove-orphans
sudo docker image prune
sudo nano requirements.txt 
sudo docker build -t airflowpids .
sudo docker compose down
sudo docker compose up -d --remove-orphans
sudo docker ps
htop
dir
cd airflowfiledir/
cd dagas
cd dags
sudo nano check_csv_dag.py
dir
cd ..
dir
cd plugins
dir
cd ..
sudo nano dags/check_csv_dag.py
sudo docker ps
dir
cd data_volume/
dir
cd ..
cd airflowdocker/
dir
cd air
cd airflowfiledir/
dir
cd dagas
cd dags
dir
cd ..
dir
find rows.csv
cd ..
find -r rows.csv
find --help
find -depth 2 rows.csv

tree . | grep rows.csv
tree .
cd ..
tree . | grep .csv
cd nash
cd ..
tree . | grep rows
dir
cd nash
tree . | grep csv
dir
cd connection_data/
doir
dir
cd ..
dir
cd pids_1/
dir
cd data
dir
mv rows.csv ../../../pids_user/
sudo mv rows.csv ../../../pids_user/
cd ../../../pids_user/
dir
cd airflowdocker/
sudo nano docker-compose.y
sudo nano docker-compose.yaml 
sudo docker ps
sudo nano docker-compose.yaml 
sudo docker compose down
sudo nano docker-compose.yaml 
sudo docker compose down
sudo docker compose up -d --remove-orphans
cd ..
dir
mkdir csv_volume
mv rows.csv csv_volume/
ls csv_volume/
cd  airflowdocker/
sudo docker compose up -d --remove-orphans
sudo docker ps
dir
cd airflowfiledir/
sudo nano dags/check_csv_dag.py
cd ..
sudo nano docker-compose.yaml 
sudo docker compose down
sudo docker compose up -d --remove-orphans
cd airflowfiledir/
sudo nano dags/check_csv_dag.py
cd ..
sudo docker compose down
sudo docker compose up -d -remove-orphans
sudo docker compose up -d --remove-orphans
sudo nano docker-compose.yaml 
cd ,,
cd ..
cd compose_cluster/
sudo nano docker-compose.yaml 
sudo docker compose down
sudo docker compose up -d --remove-orphans
sudo docker network create common_network
sudo docker compose up -d --remove-orphans
cd ..
cd airflowdocker/
sudo docker compose down
sudo docker compose up -d --remove-orphans
sudo docker ps
sudo nano airflowfiledir/dags/check_csv_dag.py
cd ..
cd compose_cluster/
sudo nano docker-compose.yaml 
sudo docker compose down
sudo docker compose up -d --remove-orphans
sudo docker exec -it airflowdocker-airflow-worker-1 ping spark-master
sudo docker exec -it airflowdocker-airflow-worker-1 curl spark-master:22
sudo docker exec -it airflowdocker-airflow-worker-1 curl spark-master
sudo docker network inspect common_network
sudo nano docker-compose.yaml 
sudo cat docker-compose.yaml 
sudo docker network ls
sudo docker exec -it airflowdocker-airflow-worker-1 /bin/bash
sudo docker inspect -f '{{range .NetworkSettings.Networks}}{{.IPAddress}}{{end}}' spark-master
sudo docker ps
sudo docker logs spark-master
sudo docker compose up -d --remove-orphans
sudo nano docker-compose.yaml 
sudo docker compose up -d --remove-orphans
sudo docker logs spark-master
cd ..
cd airflowdocker/
sudo nano airflowfiledir/dags/check_csv_dag.py
sudo docker exec -it spark-master bash
cd ..
cd compose_cluster/
sudo docker compose down 
sudo docker compose up -d --remove-orphans
sudo docker ps
sudo docker logs spark-master
cd ..
cd airflowdocker/
cd airflowfiledir/
sudo nano dags/check_csv_dag.py
sudo docker ps
sudo docker exec -it spark-master /bin/bash
cd ..
dir
cd sparkscala/
dir
sudo nano start-spark.sh 
sudo nano Dockerfile
cd ..
cd compose_cluster/
cd ..
cd airflowdocker/
cd airflowfiledir/
sudo nano dags/check_csv_dag.py
cd ..
cd sparkscala/
dir
sudo nano sshd_config 
sudo nano Dockerfile
sudo cat sshd_config 
sudo cat Dockerfile
sudo docker ps
sudo docker exec -it airflowdocker-airflow-webserver-1
sudo docker exec -it airflowdocker-airflow-webserver-1 bash
sudo docker exec -it spark-master bash
sudo docker exec -it airflowdocker-airflow-webserver-1
sudo docker exec -it airflowdocker-airflow-webserver-1 bash
sudo cat Dockerfile
dir
mv Dockerfile Dockerfile.old2
dir
sudo nano Dockerfile
sudo docker build -t sparkscala .
cd ..
cd compose_cluster/
sudo docker compose down
sudo docker compose up -d --remove-orphans
sudo docker ps
sudo docker exec -it airflowdocker-airflow-webserver-1
sudo docker exec -it airflowdocker-airflow-webserver-1 bash
sudo docker exec -it spark-master bash
cd ..
cd airflowdocker/
cd airflowfiledir/
dir
cd dags
sudo nano check_csv_dag.py
sudo cat check_csv_dag.py
dir
sudo mv check_csv_dag.py check_csv_dag.py.old3
sudo nano check_csv_dag.py
cd ../../
sudo docker compose down
sudo docker compose up -d --remove-orphans
cd airflowfiledir/
sudo cat dags/check_csv_dag.py
sudo nano dags/check_csv_dag.py
sudo docker ps
sudo docker exec -it airflowdocker-airflow-worker-1 bash
nano dags/check_csv_dag.py
sudo nano dags/check_csv_dag.py
htop
sudo docker exec -it airflowdocker-airflow-worker-1 bash
sudo docker ps
sudo docker exec -it spark-master bash
sudo docker exec -it airflowdocker-airflow-worker-1 bash
cd ..
cd sparkscala/
dir
sudo nano script1.py 
cd ..
cd airflowdocker/
cd airflowfiledir/
cd dags
sudo nano check_csv_dag.py
sudo docker exec -it airflowdocker-airflow-worker-1 bash
cd ..
sudo nano dags/check_csv_dag.py
sudo docker ps
cd ..
cd compose_cluster/
sudo nano docker-compose.yaml 
sudo docker logs pidskafka
sudo nano docker-compose.yaml 
sudo docker rm -f pidskafka
sudo docker compose up -d --remove-orphans
sudo docker logs pidskafka
docker exec -it spark-master bash
sudo docker exec -it spark-master bash
cdf ..
cd ..
cd compose_cluster/
cd ..
cd airflowdocker/
sudo nano airflowfiledir/dags/check_csv_dag.py
df -H
docker image prune
sudo docker image prune
df -H
dir
cd ..
dir
cd csv_volume/
dir
cd ..
cd data_volume/
dir
cd ..
cd compose_cluster/
sudo nano docker-compose.yaml 
dir
cd sparkprograms/
dir
cd ..
dir
cd ..
ls
cd compose_cluster/
sudo nano docker-compose.yaml 
cd ..
mkdir sparkprograms
cd compose_cluster/
dir
ls -la sparkprograms/
rm -rf sparkprograms/
cd ..
cd compose_cluster/
sudo docker compose down
sudo docker compose up -d --remove-orphans
dir
cd ..
cd spark
cd sparkprograms
cd ..
cd compose_cluster/
sudo nano docker-compose.yaml 
cd ..
cd airflowdocker/
cd airflowfiledir/
sudo nano dags/check_csv_dag.py
sudo docker image ls
sudo docker image rm ae99
sudo docker image rm -f ae99
sudo docker image rm 6db
sudo docker image rm -f 6db
sudo docker image rm f66
sudo docker image rm -f f66
df -H
sudo docker image ls
sudo docker image rm -f f0f
df -H
dir
cd ..
dir
cd spark
cd sparkscala/
sudo nano start-spark.sh 
cd ..
cd compose_cluster/
sudo docker compose down
sudo docker compose up -d --remove-orphans
sudo docker logs spark-master
cd ..
cd sparkscala/
sudo docker build -t sparkscala .
df -H
cd ..
cd compose_cluster/
sudo docker compose down
sudo docker compose up -d --remove-orphans
sudo docker logs spark-master
docker exec -it spark-master bash
sudo docker exec -it spark-master bash
df -H
sudo docker exec -it spark-master bash
sudo docker ps
sudo docker exec -it airflowdocker-airflow-webserver-1
sudo docker exec -it airflowdocker-airflow-webserver-1 bash
cd ..
dir
cd spark
cd sparkprograms/
dir
cd ..
cd compose_cluster/
sudo nano docker-compose.yaml 
cd df -H
df -H
docker image prune
sudo docker image prune  
cd ..
cd spars
cd sparkscala/
dir
sudo nano start-spark.sh 
sudo docker build -t sparkscala .
cd ..
cd compose_cluster/
sudo docker compose down
sudo docker compose up -d --remove-orphans
sudo docker logs spark-master
sudo docker exec -it spark-master
sudo docker exec -it spark-master bash
sudo docker ps
sudo docker exec -it airflowdocker-airflow-webserver-1
sudo docker exec -it airflowdocker-airflow-webserver-1 bash
docker exec -it spark-master
docker exec -it spark-master bash
sudo docker exec -it spark-master bash
sudo docker ps
sudo docker exec -it airflowdocker-airflow-webserver-1
sudo docker exec -it airflowdocker-airflow-webserver-1 bash
cd ..
cd airflowdocker/
cd airflowfiledir/
sudo nano dags/check_csv_dag.py
cd ../../sparkscala/
dir
sudo nano script1.py 
sudo nano start-spark.sh 
df -H
docker image prune
sudo docker image prune
sudo docker image ls
cd ..
cd compose_cluster/
dir
sudo nano docker-compose.yaml 
sudo docker volume ls
sudo docker volume prune
df -H
sudo docker logs spark-master
cd ..
cd sparkscala/
dir
sudo nano start-spark.sh 
sudo nano script1.py 
sudo docker build -t sparkscala .
cd ..
cd compose_cluster/
sudo docker compose down
sudo docker logs spark-master
sudo docker compose up -d --remove-orphans
sudo docker logs spark-master
sudo tail docker logs spark-master
sudo docker logs spark-master
sudo docker exec -it spark-master service ssh start
htop
df -H
sudo docker logs pidskafka
sudo docker exec -it spark-master bash
htop
cd ..
cd airflowdocker/
cd airflowfiledir/
sudo nano dags/check_csv_dag.py
sudo docker exec -it spark-master bash
sudo docker ps
sudo docker exec -it airflow-airflow-webserver-1
sudo docker exec -it airflow-airflow-webserver-1 bash
sftp sftpuser@spark-master
sudo docker exec -it spark-master bash
sudo docker exec -it airflowdocker-airflow-webserver-1
sudo docker exec -it airflowdocker-airflow-webserver-1 bash
cd ../..
cd spark
cd sparkprograms/
dir
ls
cd ..
ls
cd csv_volume/
dir
cd ..
cd compose_cluster/
sudo nano docker-compose.yaml 
sudo docker ps
sudo docker exec -it spark-master bash
sudo docker exec -it pidskaf
sudo docker exec -it pidskafka
sudo docker exec -it pidskafka bash
sudo docker ps
sudo docker exec -it spark-master service ssh start
cd ..
cd pids_user/
cd compose_cluster/
sudo docker compose up -d --remove-orphans
sudo docker exec -it spark-master service ssh start
sudo docker exec -it spark-master bash
cd ..
cd spark
cd sparkscala/
dir
sudo nano script1.py 
sudo cat script1.py 
dir
cd ..
cd air
cd airflowdocker/
cd airflowfiledir/
sudo cat dags/check_csv_dag.py
dir
cd ..
dir
cd spark
cd sparkprograms
dir
sudo docker ps
sudo docker exec -it airflowdocker-airflow-scheduler-1
sudo docker exec -it airflowdocker-airflow-scheduler-1 bash
dir
ls -la
cd ..
ls -la
cd compose_cluster/
sudo nano docker-compose.yaml 
sudo docker volume ls
sudo docker inspect compose_cluster_sparkprograms
cd ..
dir
cd airflowdocker/
cd airflowfiledir/
sudo nano dags/check_csv_dag.py
sudo docker logs pidskafka
cd ..
cd compose_cluster/
sudo docker compose down
sudo docker compose up -d --remove-orphans
sudo docker exec -it spark-master bash
sudo docker ps
sudo docker exec -it airflowdocker-airflow-webserver1
sudo docker exec -it airflowdocker-airflow-webserver1 bash
dir
sudo docker exec -it airflowdocker-airflow-webserver-1 bash
sudo docker exec -it airflowdocker-airflow-worker-1 bash
cd ..
cd airflowdocker/
sudo docker compose down
sudo docker compose up -d --remove-orphans
sudo docker ps
sudo docker exec -it airflowdocker-airflow-webserver-1
sudo docker exec -it airflowdocker-airflow-webserver-1 bash
sudo nano airflowfiledir/dags/check_csv_dag.py
sudo docker compose down
sudo docker compose up -d --remove-orphans
sudo docker ps
sudo nano airflowfiledir/dags/check_csv_dag.py
sudo docker exec -it spark-master ls /uploads
sudo docker exec -it spark-master ls -la /uploads
sudo docker logs spark-master
sudo nano airflowfiledir/dags/check_csv_dag.py
sudo docker logs spark-master
sudo docker ps
cd ..
cd airflowdocker/
sudo nano airflowfiledir/dags/check_csv_dag.py
df -H
sudo docker exec -it spark-master
sudo docker exec -it spark-master bash
sudo nano airflowfiledir/dags/check_csv_dag.py
cd ..
cd compose_cluster/
sudo docker compose down
cd ..
cd airflowdocker/
cd airflowfiledir/
dir
sudo nano dags/check_csv_dag.py
cd ..
sudo docker compose down
sudo docker compose up -d --remove-orphans
cd ..
cd compose_cluster/
sudo docker compose up -d --remove-orphans
sudo docker exec -it spark-master service ssh start
df -H
sudo docker image prune
sudo df -H
sudo docker ps
sudo docker exec -it airflowdocker-airflow-worker-1
sudo docker exec -it airflowdocker-airflow-worker-1 bash
cd ..
cd airflowdocker/
cd airflowfiledir/
sudo nano dags/check_csv_dag.py
cd ..
cd sparkscala/
sudo nano script1.py 
cd ..
cd airflowdocker/
cd airflowfiledir/
sudo nano dags/check_csv_dag.py
sudo docker logs spark-master
sudo nano dags/check_csv_dag.py
cd ..
cd compose_cluster/
sudo docker compose down
sudo docker compose up -d --remove-orphans
sudo docker exec -it spark-master service ssh start
sudo docker logs spark-master
sudo docker exec -it spark-master bash
cd ..
cd airflowdocker/
sudo nano airflowfiledir/dags/check_csv_dag.py
cd ..
cd  compose_cluster/
sudo docker compose restart
sudo docker ps
sudo docker logs spark-master
sudo docker logs pidskafka
sudo docker compose restart
sudo docker exec -it spark-master service ssh start
sudo docker logs pidskafka
sudo docker compose down
sudo docker compose up -d --remove-orphans
sudo docker logs spark-master
sudo docker ps
sudo docker exec -it spark-master service ssh start
sudo docker logs spark-master
sudo docker exec -it spark-master ls /home/sftpuser/uploads
sudo docker exec -it spark-master ls -la /home/sftpuser/uploads
sudo docker exec -it spark-master ls -lha /home/sftpuser/uploads
df -H
cd ..
cd airflowdocker/
sudo nano airflowfiledir/dags/check_csv_dag.py
sudo docker ps
sudo docker compose restart
cd airflowdocker/
sudo docker compose restart
cd ..
cd compose_cluster/
sudo docker compose down
sudo docker compose up -d --remove-orphans
sudo docker exec -it spark-master service ssh start
cd ..
cd airflowdocker/
sudo nano airflowfiledir/dags/check_csv_dag.py
curl 192.168.0.45:6001
sudo docker exec -it pidskafka bash
cd airflowfiledir/
sudo nano dags/check_csv_dag.py
df -H
sudo docker exec -it pidskafka bash
sudo docker exec -it spark-master bash
sudo docker logs spark-master
cd ../..
cd compose_cluster/
sudo docker compose down
sudo docker compose up -d --remove-orphans
sudo docker exec -it spark-master bash
sudo docker logs spark-master
cd ..
cd sparkscala/
dir
sudo nano script1.py 
sudo docker exec -it mongotainer bash
sudo docker ps
sudo docker exec -it mongotainer bash
sudo nano script1.py 
htop
df -H
sudo docker image prune
sudo docker volume prune
df -H
sudo docker logs spark-master
sudo nano script1.py 
sudo docker build -t sparkscala .
cd ..
cd compose_cluster/
sudo docker compose down
sudo docker compose up -d --remove-orphans
cd ..
cd sparkprograms/
sudo rm -f rows*
ls
sudo docker exec -it spark-master service ssh start
sudo docker logs spark-master
ls
sudo rm -f rows*
cd ..
cd compose_cluster/
sudo docker compose down
sudo docker compose up -d --remove-orphans
sudo docker exec -it spark-master service ssh start
cd ..
cd sparkprograms/
ls
sudo docker exec -it spark-master
sudo docker logs spark-master
cd ..
cd sparkscala/
sudo nano script1.py 
cd ..
cd sparkscala/
sudo docker build -t sparkscala .
sudo nano script1.py 
docker build -t sparscala .
sudo docker build -t sparscala .
ls
cd ..
cd compose_cluster/
sudo docker compose down
sudo docker compose up -d --remove-orphans
sudo docker image prune
sudo docker volume prune
cd ..
cd sparkprograms/
dir
sudo rm -f *
dir
cd ..
cd compose_cluster/
sudo docker compose down
sudo docker compose up -d --remove-orphans
sudo docker exec -it spark-master service ssh start
sudo docker logs spark-master
cd ..
cd sparkscala/
sudo nano script1.py 
sudo docker exec -it spark-master bash
sudo docker build -t sparkscala .
sudo docker build -t sparkscala . --no-cache
cd ..
rm -f sparkprograms/ rows*
rm -f sparkprograms/rows*
sudo rm -f sparkprograms/rows*
cd compose_cluster/
sudo docker compose down
sudo docker compose up -d --remove-orphans
sudo docker ps
sudo docker exec -it spark-master service ssh start
sudo docker logs spark-master
cd .. 
cd sparkscala/
sudo nano script1.py 
df -H
sudo docker image prune
sudo docker volume prune
sudo docker build -t sparkscala . --no-cache
cd ..
cd sparkprograms/
dir
cd ..
cd compose_cluster/
sudo docker compose down
sudo docker compose up -d --remove-orphans
sudo docker exec -it spark-master service ssh start
sudo docker logs spark-master
sudo docker logs pidskafka
sudo docker logs spark-master
cd ..
cd sparkscala/
sudo nano script1.py 
sudo docker build -t sparkscala . --no-cache
cd ..
sudo rm -f sparkprograms/rows*
cd com
cd compose_cluster/
sudo docker compoose down
sudo docker compose down
sudo docker compose up -d --remove-orphans
suod docker exec -it spark-master service ssh start
sudo docker exec -it spark-master service ssh start
sudo docker logs spark-master
sudo docker logs spark-master | grep part2
df -H
docker image prune
sudo docker image prune
df -H
sudo docker volume prune
df -H
docker compose down
sudo docker ps
df -H
sudo docker logs spark-master
cd sparkscala/
dir
sudo nano script1.py 
sudo docker exec -it spark-master bash
cd ..
cd sparkprograms/
dir
ls -la
cd ..
cd compose_cluster/
sudo nano docker-compose.yaml 
cd com
sudo docker compose donw
sudo docker compose down
sudo docker compose up -d --remove-orphans
sudo docker logs spark-master
sudo docker exec -it spark-master service ssh start
sudo docker logs spark-master
sudo docker logs mongotainer
sudo docker exec -it spark-master bash
cd ..
cd sparkscala/
sudo nano script1.py 
docker exec -it spark-master bash
sudo docker exec -it spark-master bash
cd ..
cd compose_cluster/
sudo docker compose down
sudo docker compose up -d --remove-orphans
sudo docker exec -it spark-master service ssh start
sudo docker logs spark-master
sudo docker exec -it spark-master service ssh start
sudo docker logs spark-master
htop
sudo docker logs spark-master
cd ..
cd sparkscala/
sudo nano s
sudo nano script1.py 
sudo docker build -t sparkscala .
cd ..
cd sparkprograms/
sudo rm -f rows*
cd ..
cd compose_cluster/
sudo docker compose down
sudo docker compose up -d --remove-orphans
sudo docker exec -it spark-master service ssh start
sudo docker logs spark-master
df -H
docker image prune
sudo docker image prune
sudo docker volume prune
sudo docker logs spark-master
sudo docker logs spark-master | grep datos
sudo docker logs spark-master | grep insertados
cd ..
cd sparkscala/
sudo nano script1.py 
sudo docker build -t sparkscala .
cd ..
cd compose_cluster/
sudo docker compose down
sudo docker compose up -d --remove-orphans
cd ..
cd spark
cd sparkprograms/
dir
rm .
rm *
ls
sudo rm -f ./*
ls
ls -la
sudo docker exec -it spark-master service ssh start
ls
ls -lha
sudo docker logs spark-master
dir
mv rows.csv.part1 ..
sudo mv rows.csv.part1 ..
sudo rm -f rows*
cd ..
mv rows.csv.part1 sparkprograms/
sudo mv rows.csv.part1 sparkprograms/
cd airflowdocker/airflowfiledir/
dir
cd dags
dir
sudo nano check_csv_dag.py
cd ../../..
dir
cd sparkprograms/
ls
rm rows.csv.part1 
ls
sudo rm rows.csv.part1 
ls
cd ..
cd compose_cluster/
sudo docker compose down
sudo docker compose up -d --remove-orphans
sudo docker exec -it spark-master service ssh start
sudo docker logs pidskafka
sudo docker logs spark-master
sudo docker ps
cd ..
clear
exit
cd airflowdocker/
sudo docker compose up -d --remove-orphans
cd ..
cd compose_cluster/
sudo docker compose up -d --remove-orphans
sudo docker exec -it spark-master service ssh start
sudo docker ps
sudo docker exec -it spark-master service ssh start
sudo docker logs spark-master
cd ..
cd sparkprograms/
ls -la
cd ..
htop
df -H
cd compose_cluster/
sudo docker compose down
sudo nano docker-compose.yaml 
cd ..
sudo rm -r sparkprograms/rows*
ls sparkprograms/
dir
cd compose_cluster/
sudo docker image prune
sudo docker volume prune
df -H
sudo docker compose up -d --remove-orphans
sudo docker exec -it spark-master service ssh start
dir
sudo docker ps
cd airflowdocker/
sudo docker compose down &
cd ..
cd compose_cluster/
sudo docker compose down &
cdc ..
pwd
cd air
cd ..
cd airflowdocker/
sudo docker compose up -d --remove-orphans
cd ..
rm -f sparkprograms/rows*
sudo rm -f sparkprograms/rows*
cd compose_cluster/
sudo docker compose up -d --remove-orphans
sudo docker compose exec -it spark-master service ssh startr
sudo docker compose exec -it spark-master service ssh start
sudo docker logs spark-master
sudo docker compose exec -it spark-master service ssh start
sudo docker ps
sudo docker exec -it spark-master
sudo docker exec -it spark-master bash
sudo docker exec -it spark-master service ssh start
sudo docker ps
ls
git push
git push --set-upstream origin main
ssh git@github.com
ssh-add -l
service ssh-add start
eval "$(ssh-agent -s)"
ssh-add -l
sudo nano ~/.bashrc
source ~/.bashrc
ssh-add ~/.ssh/id_rsa
exit
